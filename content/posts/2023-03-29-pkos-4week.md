---
title: "PKOS-4Week"
date: 2023-03-29T23:12:18+09:00
draft: false
categories: ["Kubernetes"]
slug: "pkos-4week"
aliases:
  - /pkos-4week/
  - /pkos-4week/
---

\n

이번주 스터디는 K8S에서의 Pometheus Grafana 다.

\n\n\n\n

이글은 **chatgpt를 이용해서 삽질하는 리눅서**를 담고있다.

\n\n\n\n

프로메테우스는 아이콘이 불꽃 모양인데 정말 모니터링계에 불을 가져다준 혁신과도 같은 존재다. 이전에는 Nagios / Zabbix가 나눠먹고 있었다.

\n\n\n\n

나는 이번에 뭘 모니터링 해볼까 고민하다가 HPA를 모니터링 해볼까한다.

\n\n\n\n

먼저 내가 요즘 일하는 방식을 보여줄까한다.

\n\n\n\n
![](/images/2023/03/image-9.png)
\n\n\n\n

바로 Chatgpt다.

\n\n\n\n
![](/images/2023/03/image-10.png)
\n\n\n\n

```
apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.21\n        ports:\n        - containerPort: 80\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-service\nspec:\n  selector:\n    app: nginx\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n  type: LoadBalancer\n
```

\n\n\n\n
![](/images/2023/03/image-11.png)
\n\n\n\n

```
apiVersion: autoscaling/v2beta2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: nginx-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: nginx-deployment\n  minReplicas: 3\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 50\n
```

\n\n\n\n
![](/images/2023/03/image-12.png)
\n\n\n\n

<https://github.com/rakyll/hey>

\n\n\n\n

go 기반이라 bash로 수정해달라고 했다.

\n\n\n\n
![](/images/2023/03/image-13.png)
\n\n\n\n

```
#!/bin/bash\n\nSERVICE_IP=$(kubectl get svc nginx-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\nCONCURRENCY=100\nREQUESTS=50000\n\n# Run load test\nfor i in $(seq 1 $CONCURRENCY); do\n  (for j in $(seq 1 $(($REQUESTS / $CONCURRENCY))); do\n    curl -s -o /dev/null http://${SERVICE_IP}/\n  done) &\ndone\n\n# Wait for all background processes to complete\nwait\n
```

\n\n\n\n

위의 Manifast 를 적용한 결과는 다음과 같다.

\n\n\n\n

```
 k get all \nNAME                                    READY   STATUS    RESTARTS   AGE\npod/nginx-deployment-7c6895c677-cblrh   1/1     Running   0          15s\npod/nginx-deployment-7c6895c677-s6b5c   1/1     Running   0          15s\npod/nginx-deployment-7c6895c677-smkxv   1/1     Running   0          15s\n\nNAME                    TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nservice/nginx-service   LoadBalancer   100.66.65.216   <pending>     80:30979/TCP   15s\n\nNAME                               READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/nginx-deployment   3/3     3            3           15s\n\nNAME                                          DESIRED   CURRENT   READY   AGE\nreplicaset.apps/nginx-deployment-7c6895c677   3         3         3       15s\n\nNAME                                            REFERENCE                     TARGETS         MINPODS   MAXPODS   REPLICAS   AGE\nhorizontalpodautoscaler.autoscaling/nginx-hpa   Deployment/nginx-deployment   <unknown>/50%   3         10        3          19s
```

\n\n\n\n

정말 잘동작한다.

\n\n\n\n

이제 ingress 답변을 받았다.

\n\n\n\n

```
apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-ingress\n  annotations:\n    kubernetes.io/ingress.class: alb\n    alb.ingress.kubernetes.io/scheme: internet-facing\nspec:\n  rules:\n    - http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: nginx-service\n                port:\n                  number: 80\n
```

\n\n\n\n

```
k get ingress\nNAME         CLASS    HOSTS   ADDRESS                                                                     PORTS   AGE\nmy-ingress   <none>   *       k8s-nginx-myingres-106681c1f1-1873214288.ap-northeast-2.elb.amazonaws.com   80      72s
```

\n\n\n\n

ingress - svc - deployment - hpa 구조 같은건 이제 3분이면 나온다.

\n\n\n\n

gpt가 알려준 스크립트중

\n\n\n\n

kubectl get svc nginx-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}'

\n\n\n\n

부분을

\n\n\n\n

kubectl get ingress my-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'

\n\n\n\n

다음과 같이 수정하였다.

\n\n\n\n

```
curl k8s-nginx-myingres-106681c1f1-1873214288.ap-northeast-2.elb.amazonaws.com \n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\nhtml { color-scheme: light dark; }\nbody { width: 35em; margin: 0 auto;\nfont-family: Tahoma, Verdana, Arial, sans-serif; }\n</style>\n</head>\n<body>\n<h1>Welcome to nginx!</h1>\n<p>If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.</p>\n\n<p>For online documentation and support please refer to\n<a href="http://nginx.org/">nginx.org</a>.<br/>\nCommercial support is available at\n<a href="http://nginx.com/">nginx.com</a>.</p>\n\n<p><em>Thank you for using nginx.</em></p>\n</body>\n</html>\n
```

\n\n\n\n

잘 뜬다.

\n\n\n\n

이제 공격 간다

\n\n\n\n
![](/images/2023/03/image-14.png)
\n\n\n\n

굉장한 스크립트 였다... 한방에 100개의 스크립트가 떴다...후....

\n\n\n\n

근데 nginx 는 너무 가벼운 친구라...ㅠㅠ hpa 가 잘작동하지 않았다. 리미트를 준다.

\n\n\n\n

```
        resources:\n          limits:\n            cpu: 15m\n            memory: 10Mi\n          requests:\n            cpu: 15m\n            memory: 10Mi\n            \nk get hpa\nNAME        REFERENCE                     TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\nnginx-hpa   Deployment/nginx-deployment   33%/50%   3         10        3          25m\n
```

\n\n\n\n

좋다 적절하다.

\n\n\n\n

이제 셋업은 다되었다. hpa 가 동작하는 대시보드와 hap 가 일정이상 동작해서 max 에 가 까워지면 알럿을 날릴거다.

\n\n\n\n
![](/images/2023/03/image-15.png)
\n\n\n\n\n\n\n\n

Chatgpt에게 물었고, 비슷한 쿼리를 작성했다.

\n\n\n\n

```
kube_horizontalpodautoscaler_status_desired_replicas{horizontalpodautoscaler="nginx-hpa", namespace="nginx"}
```

\n\n\n\n
![](/images/2023/03/image-16.png)
\n\n\n\n

결과는 잘 작동한다. 그럼이걸 알럿을 보낼거다.

\n\n\n\n

프로메테우스에서 graph로 grafana 에서 가져온 쿼리를 넣는다

\n\n\n\n
![](/images/2023/03/image-17.png)
\n\n\n\n

1- avg(rate(kube\_horizontalpodautoscaler\_status\_desired\_replicas{horizontalpodautoscaler="nginx-hpa", namespace="nginx"}[1m]))

\n\n\n\n

```
 k edit cm prometheus-kube-prometheus-stack-prometheus-rulefiles-0\nconfigmap/prometheus-kube-prometheus-stack-prometheus-rulefiles-0 edited\n
```

\n\n\n\n
![](/images/2023/03/image-19.png)
\n\n\n\n

edit 로 수정했다.

\n\n\n\n

추가를 하다가 잘 안되서 helm에 있는 config를 뜯어봤다. 어떤구성인지,

\n\n\n\n

```
     containers:\n      - env:\n        - name: BITNAMI_DEBUG\n          value: "false"\n        - name: NGINX_HTTP_PORT_NUMBER\n          value: "8080"\n        image: docker.io/bitnami/nginx:1.23.3-debian-11-r17\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 6\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          tcpSocket:\n            port: http\n          timeoutSeconds: 5\n        name: nginx\n        ports:\n        - containerPort: 8080\n          name: http\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          tcpSocket:\n            port: http\n          timeoutSeconds: 3\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n      - command:\n        - /usr/bin/exporter\n        - -nginx.scrape-uri\n        - http://127.0.0.1:8080/status\n        image: docker.io/bitnami/nginx-exporter:0.11.0-debian-11-r44\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /metrics\n            port: metrics\n            scheme: HTTP\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: metrics\n        ports:\n        - containerPort: 9113\n          name: metrics\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /metrics\n            port: metrics\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n      dnsPolicy: ClusterFirst\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      serviceAccount: default\n      serviceAccountName: default\n      shareProcessNamespace: false\n      terminationGracePeriodSeconds: 30\n
```

\n\n\n\n

exporter 가 사이드카로 붙어서 모니터링을 하고있었다.

\n\n\n\n

<https://github.com/nginxinc/nginx-prometheus-exporter>

\n\n\n\n\n\n\n\n

온종일 삽질의 연속이다가 오늘또 k8s에서의 프로메테우스와 그라파나 패턴을 까보면서 helm을 써야할까 하는 고민이들었다. kustomize를 고민했는데 좀더 뭘깍을지 생각해봐야겠다.

\n